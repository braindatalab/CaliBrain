{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This tutorial is available for download as a Jupyter notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Sensor Data Simulation with SensorSimulator\n\nThis tutorial demonstrates how to use the :class:`~calibrain.sensor_simulation.SensorSimulator` class\nto generate synthetic MEG/EEG sensor measurements from brain source activity. The SensorSimulator \nprojects source-level neural signals to sensor space using forward models and adds realistic noise,\ncreating controlled datasets for testing source localization algorithms, validating analysis \npipelines, and benchmarking uncertainty quantification methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Mohammad Orabe  <m.orabe@icloud.com>\n# License: AGPL-3.0 license\n# Copyright the CaliBrain contributors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Background\n\nThis tutorial focuses on simulating sensor-level MEG/EEG measurements from\nknown source activity, which forms the bridge between source simulation and\ninverse problem validation.\n\nThe SensorSimulator takes source time courses and projects them to sensor space\nusing leadfield matrices (forward models). It then adds controlled noise to create\nrealistic sensor measurements that can be used for algorithm testing and validation.\nThe class supports both fixed and free source orientations and provides precise\ncontrol over signal-to-noise ratios.\n\n**Scope:** The CaliBrain framework implements a comprehensive 7-stage pipeline for\nneuroimaging simulation and validation. This tutorial covers **sensor-level \nsimulation** - the projection of neural activity from sources to sensors with\ncontrolled noise addition. For generating source activity patterns, see the \nsource simulation tutorial. For recovering sources from sensor data, see the \nsource estimation tutorial.\n\n```text\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Leadfield   \u2502 \u2192  \u2502    Source     \u2502 \u2192  \u2503   \u2605 Sensor    \u2503 \u2192  \u2502    Source     \u2502\n\u2502 Construction  \u2502    \u2502  Simulation   \u2502    \u2503   Simulation  \u2503    \u2502  Estimation   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                      \u2193\n                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                     \u2502  Evaluation   \u2502 \u2190  \u2502 Visualization \u2502 \u2190  \u2502  Uncertainty  \u2502\n                     \u2502               \u2502    \u2502               \u2502    \u2502   Estimation  \u2502\n                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mathematical Formulation\n\nSensor-level simulation projects sources to sensors via the forward model \nand adds realistic noise to create synthetic EEG/MEG data suitable for \ntesting inverse methods and uncertainty estimation.\n\n### Forward Projection\n\nThe sensor data $\\mathbf{Y} \\in \\mathbb{R}^{M \\times T}$ is generated by \nprojecting source activity through a leadfield matrix and adding noise:\n\n\\begin{align}\\mathbf{Y} = \\mathbf{L} \\mathbf{X} + \\boldsymbol{\\epsilon}\\end{align}\n\nwhere:\n\n- $\\mathbf{L} \\in \\mathbb{R}^{M \\times N}$ is the leadfield matrix\n- $\\mathbf{X} \\in \\mathbb{R}^{N \\times T}$ is the source activity matrix  \n- $M$ is the number of sensors\n- $N$ is the number of source locations (dipoles)\n- $T$ is the number of time points\n\nThe leadfield provides the mapping from source current to sensor measurements,\nwith units typically in volts per ampere-meter (V/Am) for EEG and tesla per \nampere-meter (T/Am) for MEG.\n\n### Dipole Orientations\n\nSource activity can be modeled with different orientation constraints:\n\n**Fixed orientations**: Sources are constrained to be normal to the cortical \nsurface, reducing the source space dimensionality:\n\n\\begin{align}\\mathbf{L}_{\\text{fixed}} \\in \\mathbb{R}^{M \\times N_{\\text{vertices}}}\\end{align}\n\n**Free orientations**: Sources can point in any direction, typically represented \nas three orthogonal components per vertex:\n\n\\begin{align}\\mathbf{L}_{\\text{free}} \\in \\mathbb{R}^{M \\times 3N_{\\text{vertices}}}\\end{align}\n\nThe CaliBrain framework supports both orientation models through the \n:class:`~calibrain.leadfield_builder.LeadfieldBuilder` class.\n\n### Noise Model and Alpha-SNR Framework\n\nSensor noise is modeled as additive white Gaussian noise with precise control\nthrough the Alpha-SNR parameter $\\alpha_{\\text{SNR}}$.\n\n**Classical Signal-to-Noise Ratio**\n\nThe traditional signal-to-noise ratio is defined as the ratio of signal power\nto noise power:\n\n\\begin{align}\\text{SNR}_{\\text{linear}} = \\frac{P_{\\text{signal}}}{P_{\\text{noise}}} = \\frac{\\|\\mathbf{Y}_{\\text{clean}}\\|_F^2}{\\|\\boldsymbol{\\epsilon}\\|_F^2}\\end{align}\n\nwhere the signal and noise powers are defined as:\n\n\\begin{align}P_{\\text{signal}} = \\|\\mathbf{Y}_{\\text{clean}}\\|_F^2 = \\|\\mathbf{L}\\mathbf{X}\\|_F^2 = \\sum_{m=1}^{M} \\sum_{t=1}^{T} (\\mathbf{Y}_{\\text{clean}})_{m,t}^2\\end{align}\n\n\\begin{align}P_{\\text{noise}} = \\|\\boldsymbol{\\epsilon}\\|_F^2 = \\sum_{m=1}^{M} \\sum_{t=1}^{T} \\epsilon_{m,t}^2\\end{align}\n\nThe Frobenius norm $\\|\\cdot\\|_F$ computes the total squared magnitude across\nall sensor measurements and time points, providing a scalar measure of overall\nsignal or noise energy.\n\nIn decibel (dB) scale:\n\n\\begin{align}\\text{SNR}_{\\text{dB}} = 10 \\log_{10}(\\text{SNR}_{\\text{linear}})\\end{align}\n\n**Alpha-SNR Framework**\n\nThe Alpha-SNR parameter $\\alpha_{\\text{SNR}} \\in [0, 1]$ provides an intuitive\nrepresentation where:\n\n\\begin{align}\\alpha_{\\text{SNR}} = \\frac{P_{\\text{signal}}}{P_{\\text{signal}} + P_{\\text{noise}}}\\end{align}\n\nThis formulation offers several advantages:\n\n- $\\alpha_{\\text{SNR}} = 1.0$: Pure signal, no noise added\n- $\\alpha_{\\text{SNR}} = 0.5$: Equal signal and noise power  \n- $\\alpha_{\\text{SNR}} = 0.0$: Pure noise, no signal\n- Linear interpolation between extreme cases\n\n**Noise Scaling Factor**\n\nThe noise scaling factor $\\eta$ is derived to achieve the target Alpha-SNR:\n\n\\begin{align}\\eta = \\sqrt{\\frac{1 - \\alpha_{\\text{SNR}}}{\\alpha_{\\text{SNR}}}} \\cdot \\frac{\\|\\mathbf{Y}_{\\text{clean}}\\|_F}{\\|\\boldsymbol{\\epsilon}_{\\text{base}}\\|_F}\\end{align}\n\nwhere $\\boldsymbol{\\epsilon}_{\\text{base}} \\sim \\mathcal{N}(0, \\mathbf{I})$ is the base\nwhite noise matrix with unit variance.\n\n**SNR Conversions**\n\nThe relationships between different SNR representations are:\n\n\\begin{align}\\text{SNR}_{\\text{linear}} = \\frac{\\alpha_{\\text{SNR}}}{1 - \\alpha_{\\text{SNR}}}\\end{align}\n\n\\begin{align}\\alpha_{\\text{SNR}} = \\frac{\\text{SNR}_{\\text{linear}}}{1 + \\text{SNR}_{\\text{linear}}}\\end{align}\n\n\\begin{align}\\text{SNR}_{\\text{dB}} = 10 \\log_{10}\\left(\\frac{\\alpha_{\\text{SNR}}}{1 - \\alpha_{\\text{SNR}}}\\right)\\end{align}\n\n**Conversion Reference Table**\n\nCommon Alpha-SNR values and their classical SNR equivalents:\n\n========== ============ =======\nAlpha-SNR  Linear SNR   dB SNR\n========== ============ =======\n0.95       19.00        12.79\n0.80       4.00         6.02\n0.50       1.00         0.00\n0.20       0.25         -6.02\n0.05       0.05         -12.79\n========== ============ =======\n\nThe noise model assumes homoscedastic (uniform variance) and uncorrelated \n(white) Gaussian noise across all sensors and time points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport logging\nfrom pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The SensorSimulator Class\n\nThe :class:`~calibrain.sensor_simulation.SensorSimulator` class is located in the \n``calibrain/sensor_simulation.py`` module and serves as the core component \nfor projecting source activity to sensor measurements with controlled noise.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Class Methods\n\nThe :class:`~calibrain.sensor_simulation.SensorSimulator` class consists of three core methods:\n   - :meth:`~calibrain.sensor_simulation.SensorSimulator._project_sources_to_sensors`: Internal method for forward projection using leadfield matrices\n   - :meth:`~calibrain.sensor_simulation.SensorSimulator._add_noise`: Internal method for adding controlled Gaussian noise to clean signals\n   - :meth:`~calibrain.sensor_simulation.SensorSimulator.simulate`: Main public method for multi-trial sensor simulation. This is the main method that should be used as it wraps the core functionality.\n\nThe :class:`~calibrain.sensor_simulation.SensorSimulator` class is part of the CaliBrain package and can be imported directly as follows:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from calibrain import SensorSimulator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic Usage Example\nThe :class:`~calibrain.sensor_simulation.SensorSimulator` class expects a logger for tracking operations. However if we do not provide one, a default logger will be used.\nThe :meth:`~calibrain.sensor_simulation.SensorSimulator.simulate` function requires source data, leadfield matrices, and simulation parameters.\n\nQuick demonstration with minimal setup:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "demo_sensor_simulator = SensorSimulator()   # use default logger\n\n# We can always use the CaliBrain's utility function :func:`~calibrain.utils.inspect_object` to explore any \n# class structure and understand its available attributes and methods:\n\nfrom calibrain import utils\nfrom calibrain.utils import inspect_object\n\nclass_info = inspect_object(demo_sensor_simulator, show_private=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Demo with Random Data\n\nLet's start with a simple demonstration using random source activity and a \nsynthetic leadfield matrix to understand the core concepts:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create random source time courses (3 sources, 100 time points, 2 trials)\nn_sources_demo = 3\nn_sensors_demo = 5\nn_times_demo = 100\nn_trials_demo = 2\n\n# Random source activity for two trials: sources \u00d7 time\nnp.random.seed(16)\nx_demo_trial1 = np.random.randn(n_sources_demo, n_times_demo) # assuming (Am)\n\nnp.random.seed(84)  # Different seed for trial 2\nx_demo_trial2 = np.random.randn(n_sources_demo, n_times_demo) # assuming (Am)\n\nx_trials_demo = np.array([x_demo_trial1, x_demo_trial2])\n\n# Random leadfield matrix: sensors \u00d7 sources  \n# Scale to get realistic sensor voltages (V) from source currents (Am)\n# For EEG-like measurements: ~1e-6 V/Am (microVolts per Ampere\u00b7meter)\nL_demo = np.random.randn(n_sensors_demo, n_sources_demo) * 1e-6  # V/Am \n\nprint(f\"  - Source activity shape: {x_trials_demo.shape}\") # (trials \u00d7 sources \u00d7 time)\nprint(f\"  - Leadfield matrix shape: {L_demo.shape}\") # (sensors \u00d7 sources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the simple sensor simulation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_clean_demo, y_noisy_demo, noise_demo, noise_var_demo = demo_sensor_simulator.simulate(\n    x_trials=x_trials_demo,\n    L=L_demo,\n    orientation_type=\"fixed\",\n    alpha_SNR=0.7,  # 70% signal, 30% noise\n    n_trials=n_trials_demo,\n    global_seed=42\n)\n\nprint(f\"\\nDemo Results:\")\nprint(f\"  - Clean sensor data shape: {y_clean_demo.shape} (trials \u00d7 sensors \u00d7 time)\")\nprint(f\"  - Noisy sensor data shape: {y_noisy_demo.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Sensor values are in automatically in Tesla (T) for MEG.\n   We need to set the units manually to volts (V) for EEG. This will be useful for \n   visualization. Usually we can derive the correct units from the forward operator.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mne.io.constants import FIFF\n\nprint(demo_sensor_simulator.sensor_units) # -> Tesla (T)\n\ndemo_sensor_simulator.sensor_units = FIFF.FIFF_UNIT_V\nprint(demo_sensor_simulator.sensor_units) # -> Volts (V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Realistic Simulation Pipeline\n\nNow let's move to a more realistic example using the full CaliBrain pipeline\nwith anatomically-based leadfield matrices and physiologically-plausible \nsource activity patterns.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configure logging to see simulation progress\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(\n    level=logging.INFO, # Set to logging.DEBUG for more detailed output\n    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n    handlers=[logging.StreamHandler()]\n)\nlogger = logging.getLogger(\"SensorSimulator\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Load Leadfield Matrix\n\nNext, we need a leadfield matrix to project sources to sensors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from calibrain import LeadfieldBuilder\nfrom calibrain.utils import get_data_path\n\ndata_path = get_data_path() # Get the default calibrain/data path\n\n# Initialize leadfield builder\nleadfield_builder = LeadfieldBuilder(\n    leadfield_dir=data_path,\n    logger=logger\n)\n\n# Load leadfield matrix for a standard subject\nL = leadfield_builder.get_leadfield(\n    subject=\"fsaverage\",\n    orientation_type=\"fixed\",\n    retrieve_mode=\"load\"\n)\n\nn_sensors, n_sources = L.shape\n\nprint(f\"\\nLeadfield matrix:\")\nprint(f\"  - Contains {L.shape[0]} sensors and {L.shape[1]} sources\")\nprint(f\"  - Sensor units: {leadfield_builder.sensor_units}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Generate Source Activity\n\nFirst, we need source time courses to project to sensors. We'll use the\nSourceSimulator to create realistic ERP-like source activity:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from calibrain import SourceSimulator\n\n# Configure ERP parameters for source simulation\nerp_config = {\n    \"tmin\": -0.5,                # Start time of epoch (seconds before stimulus)\n    \"tmax\": 0.5,                 # End time of epoch (seconds after stimulus)\n    \"stim_onset\": 0,             # Stimulus onset time (relative to epoch start)\n    \"sfreq\": 250,                # Sampling frequency in Hz\n    \"fmin\": 1,                   # Minimum frequency for bandpass filter (Hz)\n    \"fmax\": 5,                   # Maximum frequency for bandpass filter (Hz)\n    \"amplitude\": 50.0,           # Amplitude scaling factor (nAm)\n    \"random_erp_timing\": True,   # Whether to randomize ERP onset and duration\n    \"erp_min_length\": 80         # Minimum ERP duration in samples\n}\n\n# Create source simulator and generate activity\nsource_simulator = SourceSimulator(ERP_config=erp_config, logger=logger)\n\n# Simulation parameters for source activity\nsource_params = {\n    \"orientation_type\": \"fixed\",  # Source orientation type\n    \"n_sources\": n_sources,       # Total number of source locations (fsaverage)\n    \"nnz\": 5,                     # Number of active sources per trial\n    \"n_trials\": 3,                # Number of trials to simulate\n    \"global_seed\": 42             # Seed for reproducibility\n}\n\n# Generate source time courses\nx_trials, x_active_indices_trials = source_simulator.simulate(**source_params)\n\nprint(f\"Generated source activity:\")\nprint(f\"  - Shape: {x_trials.shape} (trials x sources x time)\")\nprint(f\"  - Active sources per trial: {[len(indices) for indices in x_active_indices_trials]}\")\nprint(f\"  - Source units: {source_simulator.source_units}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>For an in-depth guide to the :class:`~calibrain.source_simulation.SourceSimulator` class and advanced visualization techniques, refer to the `tut-source-simulation` tutorial.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Configure Sensor Simulation\n\nNow we can create the SensorSimulator and project sources to sensors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create sensor simulator\nsensor_simulator = SensorSimulator(logger=logger)\nprint(f\"- Default sensor units: {sensor_simulator.sensor_units}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Default sensor units are set to Tesla (T) which corresponds to FIFF.FIFF_UNIT_T\n   in MNE notation for MEG magnetometer sensors. Usually, the units will be\n   automatically updated based on the leadfield matrix sensor type during simulation.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sensor_simulator.sensor_units = leadfield_builder.sensor_units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization with CaliBrain\n\nThe CaliBrain :class:`~calibrain.visualization.Visualizer` provides sophisticated plotting capabilities for\nsensor data analysis\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from calibrain import Visualizer\n\n# Create visualizer instance with output directory\nsave_path = Path(\"tutorial_results\")\nsave_path.mkdir(exist_ok=True)\n\nviz = Visualizer(base_save_path=str(save_path), logger=logger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>For an in-depth guide to the :class:`~calibrain.visualization.Visualizer` class and advanced visualization techniques, refer to the `_tut-visualization` tutorial.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configure sensor simulation parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sensor_simulation_params = {\n    \"x_trials\": x_trials,                    # Source time courses from Step 1\n    \"L\": L,                                  # Leadfield matrix from Step 2\n    \"orientation_type\": \"fixed\",             # Must match source simulation\n    \"alpha_SNR\": 0.3,                       # Signal-to-noise ratio (30% signal, 70% noise)\n    \"n_trials\": 3,                          # Number of trials (must match source trials)\n    \"global_seed\": 42                       # Seed for reproducible noise\n}\n\n# Execute sensor simulation\ny_clean_trials, y_noisy_trials, noise_trials, noise_var_trials = sensor_simulator.simulate(\n    **sensor_simulation_params\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect the sensor simulation results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"  - Clean sensor data shape: {y_clean_trials.shape} (trials x sensors x time)\")\nprint(f\"  - Noisy sensor data shape: {y_noisy_trials.shape} (trials x sensors x time)\")\nprint(f\"  - Noise data shape: {noise_trials.shape} (trials x sensors x time)\")\nprint(f\"  - Noise variance per trial: {noise_var_trials.shape} (trials x sensors)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Sensor Signals for All Trials\n\nFirst, let's visualize the clean and noisy sensor signals:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot clean sensor signals (concatenated)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "viz.plot_sensor_signals(\n    ERP_config=erp_config,\n    y_trials=y_clean_trials,                     # Only plot clean signals\n    # trial_idx = 0,\n    # channels=[0, 10],                          # or \"all\"\n    units=sensor_simulator.sensor_units,\n    mode=\"concatenate\",                          # or \"stack\"\n    title=\"Sensor Signals (All trials concatenated)\",\n    save_dir=\"data_simulation\",\n    file_name=\"sensor_concatenate_trials_clean\",\n    show=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot sensors (all trials) with selected channels: y_noisy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "viz.plot_sensor_signals(\n    ERP_config=erp_config,\n    y_trials=y_noisy_trials,                    # Only noisy signals\n    # trial_idx = 0,\n    channels=\"all\",                              # or \"all\"\n    units=sensor_simulator.sensor_units,\n    mode=\"stack\",                                # or \"stack\"\n    title=\"Sensor Signals (All Trials stacked)\",\n    save_dir=\"data_simulation\",\n    file_name=\"sensor_stack_trials_noisy\",\n    show=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot noisy sensor signals (concatenated)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "viz.plot_sensor_signals(\n    ERP_config=erp_config,\n    y_trials=y_noisy_trials,\n    # trial_idx = 0,\n    # channels=[0, 10],                           # or \"all\"\n    units=sensor_simulator.sensor_units,\n    mode=\"concatenate\",                           # or \"stack\"\n    title=\"Sensor Signals (All trials concatenated)\",\n    save_dir=\"data_simulation\",\n    file_name=\"sensor_concatenate_trials_noisy\",\n    show=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The visualization automatically handles unit conversion and scaling for optimal\n   display. MEG sensor measurements are typically displayed in femtoTesla (fT) and\n   EEG measurements in microVolts (\u00b5V).</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced SNR Configuration\n\nThe SensorSimulator supports various SNR configurations to simulate different\nexperimental conditions. Let's explore different noise levels:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### High SNR (Clean Signals)\n\nConfiguration for high signal-to-noise ratio,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "high_snr_params = {\n    \"x_trials\": x_trials,\n    \"L\": L,\n    \"orientation_type\": \"fixed\",\n    \"alpha_SNR\": 0.9,                       # 90% signal, 10% noise\n    \"n_trials\": 3,\n    \"global_seed\": 100                      # Different seed for variety\n}\n\ny_clean_high, y_noisy_high, noise_high, noise_var_high = sensor_simulator.simulate(**high_snr_params)\n\nprint(f\"\\nHigh SNR Results (\u03b1_SNR = 0.9):\")\nprint(f\"  - Signal range: [{y_clean_high.min():.2e}, {y_clean_high.max():.2e}]\")\nprint(f\"  - Noise range: [{noise_high.min():.2e}, {noise_high.max():.2e}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Low SNR (Noisy Signals)  \n\nConfiguration for low signal-to-noise ratio, typical of single-trial data\nor challenging recording conditions:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "low_snr_params = {\n    \"x_trials\": x_trials,\n    \"L\": L,\n    \"orientation_type\": \"fixed\",\n    \"alpha_SNR\": 0.1,                       # 10% signal, 90% noise\n    \"n_trials\": 3,\n    \"global_seed\": 200                      # Different seed for variety\n}\n\ny_clean_low, y_noisy_low, noise_low, noise_var_low = sensor_simulator.simulate(**low_snr_params)\n\nprint(f\"\\nLow SNR Results (\u03b1_SNR = 0.1):\")\nprint(f\"  - Signal range: [{y_clean_low.min():.2e}, {y_clean_low.max():.2e}]\")\nprint(f\"  - Noise range: [{noise_low.min():.2e}, {noise_low.max():.2e}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize SNR Comparisons\n\nCreate comparative visualizations to highlight the effect of different SNR levels:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# High SNR visualization\nviz.plot_sensor_signals(\n    ERP_config=erp_config,\n    y_trials=y_noisy_high,\n    units=leadfield_builder.sensor_units,\n    trial_idx=0,\n    title=\"High SNR (\u03b1_SNR = 0.9) - Clean vs Noisy\",\n    save_dir=\"snr_comparison\",\n    file_name=\"high_snr_comparison\",\n    show=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Low SNR visualization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "viz.plot_sensor_signals(\n    ERP_config=erp_config,\n    y_trials=y_noisy_low,\n    units=leadfield_builder.sensor_units,\n    trial_idx=0,\n    title=\"Low SNR (\u03b1_SNR = 0.1) - Clean vs Noisy\",\n    save_dir=\"snr_comparison\",\n    file_name=\"low_snr_comparison\",\n    show=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integration with CaliBrain Pipeline\n\nThe SensorSimulator is designed to work seamlessly with other CaliBrain\ncomponents in a complete neuroimaging simulation pipeline.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Example Pipeline Code**\n\nHere's a conceptual example of how :class:`~calibrain.sensor_simulation.SensorSimulator` integrates with\nother CaliBrain components:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline_example = '''\n# Complete CaliBrain simulation pipeline example\n\nfrom calibrain import (\n    LeadfieldBuilder, SourceSimulator, SensorSimulator, \n    SourceEstimator, UncertaintyEstimator, MetricEvaluator, Visualizer\n)\n\n# 1. Build leadfield matrix\nleadfield_builder = LeadfieldBuilder(...)\nL = leadfield_builder.get_leadfield(\n    subject=\"fsaverage\", \n    orientation_type=\"fixed\"\n)\n\n# 2. Simulate source activity  \nsource_simulator = SourceSimulator(ERP_config=erp_config)\nx_trials, x_active_indices = source_simulator.simulate(\n    orientation_type=\"fixed\",\n    n_sources=L.shape[1],  # Match leadfield dimensions\n    nnz=5,\n    n_trials=10\n)\n\n# 3. Simulate sensor measurements\nsensor_simulator = SensorSimulator()\ny_clean, y_noisy, noise, noise_var = sensor_simulator.simulate(\n    x_trials=x_trials,\n    L=L,\n    alpha_SNR=0.3,\n    n_trials=10\n)\n\n# 4. Estimate sources\nsource_estimator = SourceEstimator(solver=\"gamma_map\")\nsource_estimator.fit(L, y_noisy[0])\nx_hat, x_hat_indices, posterior_cov = source_estimator.predict(y_noisy[0])\n\n# 5. Estimate uncertainty (-> credible intervals)\nuncertainty_estimator = UncertaintyEstimator()\nci_lower, ci_upper, _, empirical_coverage = \\\\\n    uncertainty_estimator.get_confidence_intervals_data(\n        x=x_trials[0],\n        x_hat=x_hat,\n        posterior_cov=posterior_cov,\n        orientation_type=\"fixed\"\n    )\n\n# 6. Evaluate performance\nmetric_evaluator = MetricEvaluator()\nmetrics = metric_evaluator.evaluate(\n    x_true=x_trials[0],\n    x_hat=x_hat,\n    active_indices_true=x_active_indices[0],\n    active_indices_hat=x_hat_indices\n)\n\n# 7. Visualize results\nvisualizer = Visualizer()\nvisualizer.plot_source_comparison(x_trials, x_hat, x_active_indices)\n'''\n\nprint(f\"\\nPipeline Integration Example:\")\nprint(f\"See 'examples/run_experiments.py' and 'calibrain/benchmark.py'\")\nprint(f\"for complete working examples of integrated simulations.\")\n\nprint(f\"\\nSensor Simulation Tutorial Complete!\")\nprint(f\"Generated sensor data with shape: {y_noisy_trials.shape}\")\nprint(f\"Tutorial results saved to: {save_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}