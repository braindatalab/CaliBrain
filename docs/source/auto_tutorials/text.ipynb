{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This tutorial is available for download as a Jupyter notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# CaliBrain Library Overview: Core Components Tutorial\n\nThis tutorial provides a comprehensive introduction to the main components \nof the CaliBrain library for EEG/MEG source localization and uncertainty quantification.\n\nCaliBrain is designed to help researchers:\n1. Simulate realistic brain source activity and sensor measurements\n2. Apply source estimation algorithms (Gamma-MAP, eLORETA, etc.)\n3. Quantify uncertainty in source estimates\n4. Evaluate calibration quality of uncertainty estimates\n5. Visualize results and generate comprehensive reports\n\nAuthor: CaliBrain Development Team\nLicense: MIT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Import CaliBrain components\nfrom calibrain import (\n    Benchmark,\n    SourceSimulator, \n    SensorSimulator,\n    LeadfieldBuilder,\n    SourceEstimator,\n    UncertaintyEstimator,\n    MetricEvaluator,\n    Visualizer\n)\n\n#==============================================================================\n# 1. LEADFIELD BUILDER - Foundation of Forward Modeling\n#==============================================================================\n\ndef tutorial_leadfield_builder():\n    \"\"\"\n    LeadfieldBuilder: Creates the forward model connecting brain sources to sensors\n    \n    The leadfield matrix L maps source activity x to sensor measurements y:\n    y = L @ x + noise\n    \n    Key Features:\n    - Support for both MEG and EEG modalities\n    - Fixed and free source orientations\n    - Integration with MNE-Python for realistic head models\n    - Efficient matrix storage and loading\n    \"\"\"\n    print(\"=\" * 60)\n    print(\"1. LEADFIELD BUILDER TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # Configuration for leadfield simulation\n    leadfield_config = {\n        \"subject\": \"fsaverage\",           # Standard brain template\n        \"subjects_dir\": \"./data/subjects\", # MNE subjects directory\n        \"spacing\": \"ico4\",                # Source space resolution\n        \"modality\": \"eeg\",                # EEG or MEG\n        \"orientation\": \"fixed\",           # \"fixed\" or \"free\"\n        \"montage\": \"standard_1020\",       # EEG electrode layout\n        \"info_sfreq\": 250,               # Sampling frequency\n    }\n    \n    # Initialize leadfield builder\n    leadfield_builder = LeadfieldBuilder(config=leadfield_config)\n    \n    print(f\"Building leadfield for {leadfield_config['modality'].upper()} with {leadfield_config['orientation']} orientations...\")\n    \n    # Build or load leadfield matrix\n    leadfield_matrix = leadfield_builder.simulate()\n    \n    print(f\"Leadfield shape: {leadfield_matrix.shape}\")\n    print(f\"  - Sensors: {leadfield_matrix.shape[0]}\")\n    print(f\"  - Sources: {leadfield_matrix.shape[1]}\")\n    print(f\"  - Condition number: {np.linalg.cond(leadfield_matrix):.2e}\")\n    \n    return leadfield_matrix\n\n#==============================================================================\n# 2. SOURCE SIMULATOR - Brain Activity Generation\n#==============================================================================\n\ndef tutorial_source_simulator():\n    \"\"\"\n    SourceSimulator: Generates realistic brain source activity patterns\n    \n    Creates synthetic dipole activity with:\n    - Event-related potential (ERP) waveforms\n    - Configurable amplitude, timing, and frequency content\n    - Support for multiple active sources\n    - Realistic temporal dynamics\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"2. SOURCE SIMULATOR TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # ERP configuration - defines the temporal profile\n    ERP_config = {\n        \"tmin\": -0.5,           # Start time (seconds)\n        \"tmax\": 0.5,            # End time (seconds)\n        \"stim_onset\": 0.0,      # Stimulus onset time\n        \"sfreq\": 250,           # Sampling frequency (Hz)\n        \"fmin\": 1,              # Low-pass filter cutoff\n        \"fmax\": 5,              # High-pass filter cutoff\n        \"amplitude\": 50.0,      # Peak amplitude (nAm)\n        \"random_erp_timing\": True,  # Randomize exact timing\n    }\n    \n    # Initialize source simulator\n    source_simulator = SourceSimulator(ERP_config=ERP_config)\n    \n    # Simulation parameters\n    n_sources = 10000        # Total sources in source space\n    n_active = 5            # Number of active sources\n    n_trials = 50           # Number of trials to simulate\n    \n    print(f\"Simulating {n_active} active sources out of {n_sources} total sources...\")\n    print(f\"Generating {n_trials} trials with ERP amplitude {ERP_config['amplitude']} nAm\")\n    \n    # Generate source activity\n    source_data, active_indices = source_simulator.simulate(\n        n_sources=n_sources,\n        n_active=n_active,\n        n_trials=n_trials\n    )\n    \n    print(f\"Source data shape: {source_data.shape}\")\n    print(f\"Active source indices: {active_indices}\")\n    print(f\"Peak amplitude: {np.max(np.abs(source_data)):.2f} nAm\")\n    \n    # Visualize a sample ERP waveform\n    time_vector = np.linspace(ERP_config['tmin'], ERP_config['tmax'], source_data.shape[1])\n    active_source_activity = source_data[active_indices[0], :, 0]  # First active source, first trial\n    \n    plt.figure(figsize=(10, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(time_vector, active_source_activity)\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude (nAm)')\n    plt.title('Simulated ERP Waveform')\n    plt.axvline(0, color='r', linestyle='--', alpha=0.7, label='Stimulus onset')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.subplot(1, 2, 2)\n    plt.hist(np.max(np.abs(source_data), axis=1).flatten(), bins=50, alpha=0.7)\n    plt.xlabel('Peak Amplitude (nAm)')\n    plt.ylabel('Count')\n    plt.title('Distribution of Source Amplitudes')\n    plt.axvline(ERP_config['amplitude'], color='r', linestyle='--', label='Target amplitude')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return source_data, active_indices, time_vector\n\n#==============================================================================\n# 3. SENSOR SIMULATOR - Forward Modeling with Noise\n#==============================================================================\n\ndef tutorial_sensor_simulator(leadfield_matrix, source_data):\n    \"\"\"\n    SensorSimulator: Converts source activity to sensor measurements\n    \n    Applies the forward model: y = L @ x + noise\n    - Adds realistic sensor noise\n    - Supports different noise types (white, colored, realistic)\n    - Configurable signal-to-noise ratios\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"3. SENSOR SIMULATOR TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # Initialize sensor simulator\n    sensor_simulator = SensorSimulator()\n    \n    # Noise configuration\n    noise_levels = [0.0, 0.3, 0.7, 0.9]  # Different SNR levels\n    \n    print(\"Simulating sensor measurements with different noise levels...\")\n    \n    sensor_data_clean = None\n    sensor_data_noisy = {}\n    \n    for alpha_snr in noise_levels:\n        print(f\"  - Alpha SNR: {alpha_snr:.1f}\")\n        \n        # Generate sensor measurements\n        y_clean, y_noisy = sensor_simulator.simulate(\n            source_data=source_data,\n            leadfield=leadfield_matrix,\n            alpha_SNR=alpha_snr,\n            noise_type=\"white\"\n        )\n        \n        if sensor_data_clean is None:\n            sensor_data_clean = y_clean\n            \n        sensor_data_noisy[alpha_snr] = y_noisy\n        \n        # Calculate actual SNR\n        signal_power = np.var(y_clean)\n        noise_power = np.var(y_noisy - y_clean)\n        actual_snr_db = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else np.inf\n        \n        print(f\"    Actual SNR: {actual_snr_db:.1f} dB\")\n    \n    print(f\"Sensor data shape: {sensor_data_clean.shape}\")\n    print(f\"  - Channels: {sensor_data_clean.shape[0]}\")\n    print(f\"  - Time points: {sensor_data_clean.shape[1]}\")\n    print(f\"  - Trials: {sensor_data_clean.shape[2]}\")\n    \n    # Visualize sensor data\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    time_vector = np.linspace(-0.5, 0.5, sensor_data_clean.shape[1])\n    \n    for i, alpha_snr in enumerate([0.0, 0.3, 0.7, 0.9]):\n        ax = axes[i//2, i%2]\n        \n        # Plot first few channels\n        for ch in range(min(5, sensor_data_noisy[alpha_snr].shape[0])):\n            ax.plot(time_vector, sensor_data_noisy[alpha_snr][ch, :, 0], alpha=0.7)\n        \n        ax.set_xlabel('Time (s)')\n        ax.set_ylabel('Amplitude (V)')\n        ax.set_title(f'Sensor Data (\u03b1_SNR = {alpha_snr:.1f})')\n        ax.axvline(0, color='r', linestyle='--', alpha=0.5)\n        ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return sensor_data_clean, sensor_data_noisy\n\n#==============================================================================\n# 4. SOURCE ESTIMATOR - Inverse Problem Solving\n#==============================================================================\n\ndef tutorial_source_estimator(sensor_data, leadfield_matrix):\n    \"\"\"\n    SourceEstimator: Solves the inverse problem to estimate brain sources\n    \n    Implements multiple algorithms:\n    - Gamma-MAP: Hierarchical Bayesian approach with automatic relevance determination\n    - eLORETA: Exact low-resolution electromagnetic tomography\n    - sLORETA: Standardized LORETA\n    - dSPM: Dynamic statistical parametric mapping\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"4. SOURCE ESTIMATOR TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # Initialize source estimator\n    source_estimator = SourceEstimator()\n    \n    # Test different algorithms\n    algorithms = ['gamma_map', 'eloreta', 'sloreta', 'dspm']\n    \n    source_estimates = {}\n    \n    for algorithm in algorithms:\n        print(f\"\\nTesting {algorithm.upper()} algorithm...\")\n        \n        # Algorithm-specific parameters\n        if algorithm == 'gamma_map':\n            params = {\n                'alpha': 0.01,           # Regularization parameter\n                'beta': 1.0,             # Noise precision\n                'max_iter': 100,         # Maximum iterations\n                'tol': 1e-4             # Convergence tolerance\n            }\n        else:\n            params = {\n                'alpha': 0.01           # Regularization parameter\n            }\n        \n        try:\n            # Estimate sources\n            estimated_sources = source_estimator.estimate(\n                sensor_data=sensor_data[:, :, 0],  # Use first trial\n                leadfield=leadfield_matrix,\n                method=algorithm,\n                **params\n            )\n            \n            source_estimates[algorithm] = estimated_sources\n            \n            print(f\"  Estimated sources shape: {estimated_sources.shape}\")\n            print(f\"  Peak amplitude: {np.max(np.abs(estimated_sources)):.2e}\")\n            print(f\"  Sparsity (% zero): {100 * np.mean(np.abs(estimated_sources) < 1e-10):.1f}%\")\n            \n        except Exception as e:\n            print(f\"  Error with {algorithm}: {str(e)}\")\n            source_estimates[algorithm] = None\n    \n    # Visualize source estimates\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    \n    for i, algorithm in enumerate(algorithms):\n        ax = axes[i//2, i%2]\n        \n        if source_estimates[algorithm] is not None:\n            # Plot source amplitude over time\n            max_amplitude = np.max(np.abs(source_estimates[algorithm]), axis=1)\n            ax.stem(range(len(max_amplitude)), max_amplitude, basefmt=' ')\n            ax.set_xlabel('Source Index')\n            ax.set_ylabel('Max Amplitude')\n            ax.set_title(f'{algorithm.upper()} Source Estimates')\n            ax.set_yscale('log')\n        else:\n            ax.text(0.5, 0.5, f'{algorithm.upper()}\\nNot Available', \n                   ha='center', va='center', transform=ax.transAxes)\n        \n        ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return source_estimates\n\n#==============================================================================\n# 5. UNCERTAINTY ESTIMATOR - Confidence Interval Computation\n#==============================================================================\n\ndef tutorial_uncertainty_estimator(sensor_data, leadfield_matrix, source_estimates):\n    \"\"\"\n    UncertaintyEstimator: Quantifies uncertainty in source estimates\n    \n    Computes confidence intervals using:\n    - Posterior covariance from Bayesian methods\n    - Bootstrap resampling\n    - Cross-validation estimates\n    - Theoretical approximations\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"5. UNCERTAINTY ESTIMATOR TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # Initialize uncertainty estimator\n    uncertainty_estimator = UncertaintyEstimator()\n    \n    # Choose method with available source estimates\n    available_method = None\n    for method in ['gamma_map', 'eloreta', 'sloreta']:\n        if source_estimates.get(method) is not None:\n            available_method = method\n            break\n    \n    if available_method is None:\n        print(\"No source estimates available for uncertainty quantification\")\n        return None\n    \n    print(f\"Computing uncertainty for {available_method.upper()} estimates...\")\n    \n    # Configuration for uncertainty estimation\n    confidence_levels = [0.68, 0.95, 0.99]  # 1\u03c3, 2\u03c3, 3\u03c3 confidence intervals\n    \n    uncertainty_results = {}\n    \n    for conf_level in confidence_levels:\n        print(f\"\\nComputing {conf_level:.0%} confidence intervals...\")\n        \n        try:\n            # Estimate uncertainty\n            lower_bounds, upper_bounds, point_estimates = uncertainty_estimator.estimate(\n                sensor_data=sensor_data[:, :, :10],  # Use first 10 trials\n                leadfield=leadfield_matrix,\n                method=available_method,\n                confidence_level=conf_level,\n                n_bootstrap=100  # Number of bootstrap samples\n            )\n            \n            uncertainty_results[conf_level] = {\n                'lower': lower_bounds,\n                'upper': upper_bounds,\n                'point': point_estimates\n            }\n            \n            # Calculate interval widths\n            interval_widths = upper_bounds - lower_bounds\n            \n            print(f\"  Confidence intervals computed successfully\")\n            print(f\"  Mean interval width: {np.mean(interval_widths):.2e}\")\n            print(f\"  Median interval width: {np.median(interval_widths):.2e}\")\n            \n        except Exception as e:\n            print(f\"  Error computing {conf_level:.0%} CI: {str(e)}\")\n            uncertainty_results[conf_level] = None\n    \n    # Visualize uncertainty estimates\n    if len(uncertainty_results) > 0:\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n        \n        for i, conf_level in enumerate(confidence_levels):\n            if uncertainty_results[conf_level] is not None:\n                result = uncertainty_results[conf_level]\n                \n                # Plot confidence intervals for first time point\n                source_indices = range(min(100, len(result['point'])))\n                \n                axes[i].fill_between(source_indices, \n                                   result['lower'][:len(source_indices), 0],\n                                   result['upper'][:len(source_indices), 0],\n                                   alpha=0.3, label=f'{conf_level:.0%} CI')\n                axes[i].plot(source_indices, result['point'][:len(source_indices), 0], \n                           'k-', label='Point estimate')\n                \n                axes[i].set_xlabel('Source Index')\n                axes[i].set_ylabel('Amplitude')\n                axes[i].set_title(f'{conf_level:.0%} Confidence Intervals')\n                axes[i].legend()\n                axes[i].grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()\n    \n    return uncertainty_results\n\n#==============================================================================\n# 6. METRIC EVALUATOR - Performance Assessment\n#==============================================================================\n\ndef tutorial_metric_evaluator(true_sources, estimated_sources, uncertainty_results, active_indices):\n    \"\"\"\n    MetricEvaluator: Evaluates the quality of source estimates and uncertainty quantification\n    \n    Computes metrics including:\n    - Localization error (distance between true and estimated sources)\n    - False positive/negative rates\n    - Calibration scores (reliability of confidence intervals)\n    - Coverage probabilities\n    - Sharpness of uncertainty estimates\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"6. METRIC EVALUATOR TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # Initialize metric evaluator\n    metric_evaluator = MetricEvaluator()\n    \n    # Find available estimates\n    available_method = None\n    for method in estimated_sources:\n        if estimated_sources[method] is not None:\n            available_method = method\n            break\n    \n    if available_method is None:\n        print(\"No source estimates available for evaluation\")\n        return None\n    \n    print(f\"Evaluating {available_method.upper()} estimates...\")\n    \n    # Prepare ground truth\n    true_source_locations = active_indices\n    estimated_data = estimated_sources[available_method]\n    \n    try:\n        # Compute localization metrics\n        localization_metrics = metric_evaluator.compute_localization_metrics(\n            true_sources=true_sources,\n            estimated_sources=estimated_data,\n            true_active_indices=true_source_locations\n        )\n        \n        print(\"\\nLocalization Metrics:\")\n        for metric, value in localization_metrics.items():\n            print(f\"  {metric}: {value:.4f}\")\n        \n        # Compute calibration metrics if uncertainty is available\n        if uncertainty_results and len(uncertainty_results) > 0:\n            print(\"\\nCalibration Metrics:\")\n            \n            for conf_level in uncertainty_results:\n                if uncertainty_results[conf_level] is not None:\n                    result = uncertainty_results[conf_level]\n                    \n                    calibration_metrics = metric_evaluator.compute_calibration_metrics(\n                        true_sources=true_sources,\n                        lower_bounds=result['lower'],\n                        upper_bounds=result['upper'],\n                        confidence_level=conf_level\n                    )\n                    \n                    print(f\"\\n  {conf_level:.0%} Confidence Intervals:\")\n                    for metric, value in calibration_metrics.items():\n                        print(f\"    {metric}: {value:.4f}\")\n        \n        # Visualization of evaluation results\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n        \n        # Plot 1: True vs Estimated amplitude correlation\n        true_amplitudes = np.max(np.abs(true_sources), axis=1)\n        est_amplitudes = np.max(np.abs(estimated_data), axis=1)\n        \n        axes[0].scatter(true_amplitudes, est_amplitudes, alpha=0.6)\n        axes[0].plot([0, np.max(true_amplitudes)], [0, np.max(true_amplitudes)], 'r--', alpha=0.7)\n        axes[0].set_xlabel('True Amplitude')\n        axes[0].set_ylabel('Estimated Amplitude')\n        axes[0].set_title('True vs Estimated Amplitudes')\n        axes[0].grid(True, alpha=0.3)\n        \n        # Plot 2: ROC-like curve for source detection\n        thresholds = np.logspace(-6, -1, 50)\n        tpr_list, fpr_list = [], []\n        \n        for threshold in thresholds:\n            detected_sources = np.where(np.max(np.abs(estimated_data), axis=1) > threshold)[0]\n            \n            tp = len(np.intersect1d(detected_sources, active_indices))\n            fp = len(detected_sources) - tp\n            fn = len(active_indices) - tp\n            tn = len(estimated_data) - len(active_indices) - fp\n            \n            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n            \n            tpr_list.append(tpr)\n            fpr_list.append(fpr)\n        \n        axes[1].plot(fpr_list, tpr_list, 'b-', linewidth=2)\n        axes[1].plot([0, 1], [0, 1], 'r--', alpha=0.7)\n        axes[1].set_xlabel('False Positive Rate')\n        axes[1].set_ylabel('True Positive Rate')\n        axes[1].set_title('Source Detection Performance')\n        axes[1].grid(True, alpha=0.3)\n        \n        # Plot 3: Calibration plot if uncertainty available\n        if uncertainty_results and 0.95 in uncertainty_results and uncertainty_results[0.95] is not None:\n            result = uncertainty_results[0.95]\n            \n            # Compute empirical coverage for different regions\n            n_bins = 10\n            coverage_empirical = []\n            coverage_nominal = []\n            \n            for i in range(n_bins):\n                start_idx = i * len(true_sources) // n_bins\n                end_idx = (i + 1) * len(true_sources) // n_bins\n                \n                true_slice = true_sources[start_idx:end_idx]\n                lower_slice = result['lower'][start_idx:end_idx]\n                upper_slice = result['upper'][start_idx:end_idx]\n                \n                # Check coverage\n                coverage = np.mean((true_slice >= lower_slice) & (true_slice <= upper_slice))\n                coverage_empirical.append(coverage)\n                coverage_nominal.append(0.95)  # Nominal 95% coverage\n            \n            axes[2].plot(coverage_nominal, coverage_empirical, 'bo-')\n            axes[2].plot([0, 1], [0, 1], 'r--', alpha=0.7)\n            axes[2].set_xlabel('Nominal Coverage')\n            axes[2].set_ylabel('Empirical Coverage')\n            axes[2].set_title('Calibration Plot')\n            axes[2].grid(True, alpha=0.3)\n        else:\n            axes[2].text(0.5, 0.5, 'Uncertainty\\nNot Available', \n                        ha='center', va='center', transform=axes[2].transAxes)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        return localization_metrics\n        \n    except Exception as e:\n        print(f\"Error in metric evaluation: {str(e)}\")\n        return None\n\n#==============================================================================\n# 7. VISUALIZER - Comprehensive Plotting and Analysis\n#==============================================================================\n\ndef tutorial_visualizer(source_data, sensor_data, estimated_sources, active_indices, time_vector):\n    \"\"\"\n    Visualizer: Creates comprehensive plots and visualizations\n    \n    Provides visualization for:\n    - Source activity patterns over time\n    - Sensor measurement topographies\n    - Source estimate comparisons\n    - Uncertainty quantification plots\n    - Calibration analysis\n    - Interactive brain plots (when MNE is available)\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"7. VISUALIZER TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # Initialize visualizer\n    visualizer = Visualizer(base_save_path=\"./tutorial_figures\")\n    \n    print(\"Creating comprehensive visualizations...\")\n    \n    try:\n        # Create a comprehensive figure\n        fig = plt.figure(figsize=(16, 12))\n        \n        # 1. Source activity over time\n        ax1 = plt.subplot(3, 4, 1)\n        for i, idx in enumerate(active_indices[:3]):  # First 3 active sources\n            plt.plot(time_vector, source_data[idx, :, 0], label=f'Source {idx}')\n        plt.xlabel('Time (s)')\n        plt.ylabel('Amplitude (nAm)')\n        plt.title('True Source Activity')\n        plt.legend()\n        plt.grid(True, alpha=0.3)\n        plt.axvline(0, color='r', linestyle='--', alpha=0.5)\n        \n        # 2. Sensor topography at peak time\n        ax2 = plt.subplot(3, 4, 2)\n        peak_time_idx = np.argmax(np.abs(sensor_data[:, :, 0]).sum(axis=0))\n        sensor_values = sensor_data[:, peak_time_idx, 0]\n        \n        # Simple topography plot (circular arrangement)\n        angles = np.linspace(0, 2*np.pi, len(sensor_values), endpoint=False)\n        x = np.cos(angles)\n        y = np.sin(angles)\n        scatter = plt.scatter(x, y, c=sensor_values, cmap='RdBu_r', s=100)\n        plt.colorbar(scatter, ax=ax2, shrink=0.8)\n        plt.title('Sensor Topography')\n        plt.axis('equal')\n        plt.axis('off')\n        \n        # 3. Source estimate comparison\n        ax3 = plt.subplot(3, 4, 3)\n        available_method = None\n        for method in estimated_sources:\n            if estimated_sources[method] is not None:\n                available_method = method\n                break\n        \n        if available_method:\n            true_amplitudes = np.max(np.abs(source_data), axis=(1, 2))\n            est_amplitudes = np.max(np.abs(estimated_sources[available_method]), axis=1)\n            \n            plt.scatter(true_amplitudes, est_amplitudes, alpha=0.6)\n            max_amp = max(np.max(true_amplitudes), np.max(est_amplitudes))\n            plt.plot([0, max_amp], [0, max_amp], 'r--', alpha=0.7)\n            plt.xlabel('True Amplitude')\n            plt.ylabel('Estimated Amplitude')\n            plt.title(f'{available_method.upper()} Estimates')\n            plt.grid(True, alpha=0.3)\n        \n        # 4. Active source detection\n        ax4 = plt.subplot(3, 4, 4)\n        if available_method:\n            source_indices = np.arange(len(est_amplitudes))\n            colors = ['red' if idx in active_indices else 'blue' for idx in source_indices]\n            plt.scatter(source_indices[:200], est_amplitudes[:200], c=colors[:200], alpha=0.6)\n            plt.xlabel('Source Index')\n            plt.ylabel('Estimated Amplitude')\n            plt.title('Source Detection (Red=True Active)')\n            plt.yscale('log')\n            plt.grid(True, alpha=0.3)\n        \n        # 5-8. Time course plots for different noise levels\n        if isinstance(sensor_data, dict):  # Multiple noise levels\n            for i, (noise_level, data) in enumerate(list(sensor_data.items())[:4]):\n                ax = plt.subplot(3, 4, 5 + i)\n                \n                # Plot first few channels\n                for ch in range(min(3, data.shape[0])):\n                    plt.plot(time_vector, data[ch, :, 0], alpha=0.7, label=f'Ch {ch+1}')\n                \n                plt.xlabel('Time (s)')\n                plt.ylabel('Amplitude (V)')\n                plt.title(f'Sensor Data (\u03b1={noise_level:.1f})')\n                plt.grid(True, alpha=0.3)\n                plt.axvline(0, color='r', linestyle='--', alpha=0.5)\n                if i == 0:\n                    plt.legend()\n        \n        # 9. Source power spectrum\n        ax9 = plt.subplot(3, 4, 9)\n        if len(active_indices) > 0:\n            source_signal = source_data[active_indices[0], :, 0]\n            freqs = np.fft.fftfreq(len(source_signal), 1/250)\n            fft_signal = np.abs(np.fft.fft(source_signal))\n            \n            # Plot positive frequencies only\n            pos_freqs = freqs[:len(freqs)//2]\n            pos_fft = fft_signal[:len(freqs)//2]\n            \n            plt.semilogy(pos_freqs, pos_fft)\n            plt.xlabel('Frequency (Hz)')\n            plt.ylabel('Power')\n            plt.title('Source Power Spectrum')\n            plt.grid(True, alpha=0.3)\n            plt.xlim(0, 25)\n        \n        # 10. Noise analysis\n        ax10 = plt.subplot(3, 4, 10)\n        if isinstance(sensor_data, dict):\n            noise_levels = list(sensor_data.keys())\n            snr_values = []\n            \n            for noise_level in noise_levels:\n                if 'clean' in locals():\n                    signal_power = np.var(sensor_data_clean)\n                    total_power = np.var(sensor_data[noise_level])\n                    snr_db = 10 * np.log10(signal_power / (total_power - signal_power + 1e-10))\n                    snr_values.append(snr_db)\n            \n            if snr_values:\n                plt.plot(noise_levels, snr_values, 'bo-')\n                plt.xlabel('Alpha SNR')\n                plt.ylabel('Actual SNR (dB)')\n                plt.title('SNR vs Noise Level')\n                plt.grid(True, alpha=0.3)\n        \n        # 11. Estimation error over time\n        ax11 = plt.subplot(3, 4, 11)\n        if available_method and len(active_indices) > 0:\n            true_signal = source_data[active_indices[0], :, 0]\n            est_signal = estimated_sources[available_method][active_indices[0], :]\n            \n            error = np.abs(true_signal - est_signal)\n            plt.plot(time_vector, error)\n            plt.xlabel('Time (s)')\n            plt.ylabel('Absolute Error')\n            plt.title('Estimation Error Over Time')\n            plt.grid(True, alpha=0.3)\n            plt.axvline(0, color='r', linestyle='--', alpha=0.5)\n        \n        # 12. Summary statistics\n        ax12 = plt.subplot(3, 4, 12)\n        stats_text = f\"\"\"\n        SIMULATION SUMMARY\n        \n        Total Sources: {source_data.shape[0]}\n        Active Sources: {len(active_indices)}\n        Time Points: {source_data.shape[1]}\n        Trials: {source_data.shape[2]}\n        \n        Peak True Amplitude: \n        {np.max(np.abs(source_data)):.2e} nAm\n        \n        \"\"\"\n        \n        if available_method:\n            stats_text += f\"\"\"\n        Estimation Method: {available_method.upper()}\n        Peak Est. Amplitude:\n        {np.max(np.abs(estimated_sources[available_method])):.2e} nAm\n        \"\"\"\n        \n        plt.text(0.1, 0.9, stats_text, transform=ax12.transAxes, \n                fontfamily='monospace', fontsize=10, verticalalignment='top')\n        plt.axis('off')\n        \n        plt.suptitle('CaliBrain Library Tutorial: Comprehensive Analysis', fontsize=16, y=0.95)\n        plt.tight_layout()\n        plt.show()\n        \n        print(\"Visualizations created successfully!\")\n        print(f\"Figures would be saved to: {visualizer.base_save_path}\")\n        \n    except Exception as e:\n        print(f\"Error in visualization: {str(e)}\")\n\n#==============================================================================\n# 8. BENCHMARK - Automated Experimental Pipeline\n#==============================================================================\n\ndef tutorial_benchmark():\n    \"\"\"\n    Benchmark: Automated pipeline for comprehensive evaluation\n    \n    The Benchmark class orchestrates the entire workflow:\n    - Configures simulation parameters\n    - Runs experiments across parameter grids\n    - Collects and organizes results\n    - Generates comprehensive reports\n    - Supports parallel execution for large-scale studies\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"8. BENCHMARK TUTORIAL\")\n    print(\"=\" * 60)\n    \n    # Configure the benchmark experiment\n    ERP_config = {\n        \"tmin\": -0.5,\n        \"tmax\": 0.5,\n        \"sfreq\": 250,\n        \"amplitude\": 30.0,\n    }\n    \n    # Parameter grid for systematic evaluation\n    data_param_grid = {\n        \"subject\": [\"fsaverage\"],\n        \"nnz\": [1, 5, 10],              # Number of active sources\n        \"orientation_type\": [\"fixed\"],   # Source orientation\n        \"alpha_SNR\": [0.0, 0.5, 0.9],  # Noise levels\n    }\n    \n    print(\"Configuring benchmark experiment...\")\n    print(f\"ERP amplitude: {ERP_config['amplitude']} nAm\")\n    print(f\"Active sources: {data_param_grid['nnz']}\")\n    print(f\"Noise levels: {data_param_grid['alpha_SNR']}\")\n    \n    # Initialize benchmark\n    benchmark = Benchmark(\n        ERP_config=ERP_config,\n        data_param_grid=data_param_grid,\n        experiment_dir=\"./benchmark_results\"\n    )\n    \n    print(\"\\nRunning benchmark experiment...\")\n    print(\"This would typically involve:\")\n    print(\"  1. Loading/generating leadfield matrices\")\n    print(\"  2. Simulating source activity for each condition\")\n    print(\"  3. Adding noise at specified SNR levels\")\n    print(\"  4. Applying source estimation algorithms\")\n    print(\"  5. Computing uncertainty estimates\")\n    print(\"  6. Evaluating calibration metrics\")\n    print(\"  7. Generating comprehensive reports\")\n    \n    # Demonstrate benchmark configuration\n    try:\n        # This would run the full benchmark\n        # results = benchmark.run(nruns=3)\n        \n        # Instead, show what the results would look like\n        print(\"\\nExpected results structure:\")\n        print(\"results.columns = [\")\n        print(\"    'subject', 'nnz', 'alpha_SNR', 'orientation_type',\")\n        print(\"    'localization_error', 'false_positive_rate',\") \n        print(\"    'calibration_score', 'coverage_68', 'coverage_95',\")\n        print(\"    'sharpness', 'computation_time'\")\n        print(\"]\")\n        \n        # Show example parameter combinations\n        print(f\"\\nTotal parameter combinations: {len(data_param_grid['nnz']) * len(data_param_grid['alpha_SNR'])}\")\n        print(\"Parameter combinations:\")\n        for nnz in data_param_grid['nnz']:\n            for alpha_snr in data_param_grid['alpha_SNR']:\n                print(f\"  - {nnz} active sources, \u03b1_SNR = {alpha_snr}\")\n        \n    except Exception as e:\n        print(f\"Benchmark simulation: {str(e)}\")\n    \n    print(\"\\nBenchmark tutorial completed!\")\n\n#==============================================================================\n# MAIN TUTORIAL FUNCTION\n#==============================================================================\n\ndef run_complete_tutorial():\n    \"\"\"\n    Run the complete CaliBrain library tutorial\n    \n    This function demonstrates the full workflow of the CaliBrain library,\n    from leadfield generation to final evaluation and visualization.\n    \"\"\"\n    print(\"=\" * 80)\n    print(\"CALIBRAIN LIBRARY TUTORIAL\")\n    print(\"Comprehensive Introduction to Brain Source Localization and Uncertainty Quantification\")\n    print(\"=\" * 80)\n    \n    try:\n        # 1. Build leadfield matrix\n        leadfield_matrix = tutorial_leadfield_builder()\n        \n        # 2. Simulate source activity\n        source_data, active_indices, time_vector = tutorial_source_simulator()\n        \n        # 3. Simulate sensor measurements\n        sensor_data_clean, sensor_data_noisy = tutorial_sensor_simulator(\n            leadfield_matrix, source_data\n        )\n        \n        # 4. Estimate sources\n        source_estimates = tutorial_source_estimator(\n            sensor_data_clean, leadfield_matrix\n        )\n        \n        # 5. Quantify uncertainty\n        uncertainty_results = tutorial_uncertainty_estimator(\n            sensor_data_clean, leadfield_matrix, source_estimates\n        )\n        \n        # 6. Evaluate performance\n        evaluation_metrics = tutorial_metric_evaluator(\n            source_data, source_estimates, uncertainty_results, active_indices\n        )\n        \n        # 7. Create visualizations\n        tutorial_visualizer(\n            source_data, sensor_data_clean, source_estimates, \n            active_indices, time_vector\n        )\n        \n        # 8. Demonstrate benchmark workflow\n        tutorial_benchmark()\n        \n        print(\"\\n\" + \"=\" * 80)\n        print(\"TUTORIAL COMPLETED SUCCESSFULLY!\")\n        print(\"=\" * 80)\n        print(\"\\nNext steps:\")\n        print(\"1. Explore the examples/ directory for more specific use cases\")\n        print(\"2. Read the API documentation for detailed parameter descriptions\")\n        print(\"3. Try the benchmark on your own data\")\n        print(\"4. Customize algorithms and parameters for your research needs\")\n        print(\"\\nFor more information:\")\n        print(\"- Documentation: https://braindatalab.github.io/CaliBrain/\")\n        print(\"- GitHub: https://github.com/braindatalab/CaliBrain\")\n        print(\"- Issues: https://github.com/braindatalab/CaliBrain/issues\")\n        \n    except Exception as e:\n        print(f\"\\nTutorial error: {str(e)}\")\n        print(\"This is a demonstration - actual implementation may vary.\")\n\nif __name__ == \"__main__\":\n    \"\"\"\n    Run the tutorial when script is executed directly\n    \"\"\"\n    run_complete_tutorial()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}